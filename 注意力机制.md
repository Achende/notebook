# 注意力机制的注意事项 #

***1、词***

每个词都有一个高维初始向量（嵌入向量），在向量头（index=0）是它在句子中的位置索引（非自带，在句子中加上去的）



## 1. 回顾与背景 (Previously: Transformers)

*   **核心目标**: Transformer (特指类似 GPT 的模型) 的任务是根据输入的文本序列预测下一个最可能的词。
*   **Tokens & Embeddings**:
    *   输入文本被分解成 **Tokens** (词或词的一部分)。
    *   每个 Token 被转换成一个高维向量，称为 **Embedding** (词嵌入)。
*   **语义向量空间**:
    *   词嵌入的关键在于，高维向量空间中的 **方向** 可以捕捉词语间的 **语义关系**。
    *   例子：`国王 - 男人 + 女人 ≈ 女王`，或 `叔叔 -> 阿姨` 的向量差 ≈ `男人 -> 女人` 的向量差。视频展示了性别、大小等概念如何体现为方向。

## 2. Attention 机制的必要性 (Why Attention?)

*   **初始 Embedding 的局限性**: 初始词嵌入是 **上下文无关** 的。
    *   例如，单词 `mole` 可以指鼹鼠、摩尔或痣，但其初始嵌入向量相同。
*   **目标**: Transformer 需要逐步 **调整 (refine)** 这些初始嵌入，使其 **包含上下文信息**。Attention 机制是实现此目标的核心。
*   **例子**:
    *   `mole` 在不同句子中的含义需要区分："American shrew mole" vs "One mole of carbon dioxide" vs "Take a biopsy of the mole"。
    *   `Tower` 在 "Eiffel Tower" 中应与巴黎、钢铁相关，但在 "Miniature Eiffel Tower" 中不应与“高大”相关。

## 3. Attention 机制的核心思想 (What is Attention supposed to do?)

*   **信息传递**: Attention 允许模型中不同 Token 之间传递信息。
*   **加权求和**: 一个 Token 的新表示是通过对序列中 **所有** Token 的某种表示进行 **加权求和** 得到的。关键在于计算 **权重 (weights)**，即一个 Token 应“注意”其他 Token 多少。

## 4. Attention 的计算过程 (Query, Key, Value - QKV)

1.  **生成 Q, K, V**:
    *   对 **每个** 输入 Token 的嵌入向量 (`E`)，通过乘以三个不同的、**可学习的** 权重矩阵 (`WQ`, `WK`, `WV`)，生成三个新向量：
        *   **Query (Q) 向量**: 代表当前 Token “想要查询”什么信息。 (e.g., `creature` 问："附近有形容词吗？")
        *   **Key (K) 向量**: 代表当前 Token 能 “提供”什么信息或“标签”。 (e.g., `fluffy` 说："我是形容词，描述后面的名词。")
        *   **Value (V) 向量**: 代表当前 Token 实际 “携带”并准备传递的信息。
2.  **计算相关性分数 (Scores)**:
    *   特定 Token (如 `creature`) 的 Query 向量 (`Q4`) 与序列中 **所有** Token 的 Key 向量 (`K1`...`K8`) 进行 **点积 (dot product)**。结果越大，表示 Query 与 Key 越相关。
3.  **缩放 (Scaling)**:
    *   将点积分数除以 Key/Query 向量维度的平方根 (`√dk`)，以稳定训练。
4.  **计算权重 (Softmax)**:
    *   对每个 Query 计算出的所有（缩放后）分数应用 **Softmax** 函数，得到一组 **非负且总和为 1** 的权重。这表示当前 Token 应分配多少“注意力”给其他 Token。
5.  **加权求和 Value**:
    *   使用 Softmax 权重对 **所有** Token 的 Value 向量进行 **加权求和**：
        `Output_i = sum(softmax_scores_i * V_j for j in all_tokens)`
    *   结果是 Token i 融合了上下文信息的新表示。
*   **Attention Pattern**: QK 点积或 Softmax 权重可视化为网格，显示词间注意力分布。

## 5. 掩码 (Masking)

*   在解码器模型 (如 GPT) 中，预测时模型不能“看到”未来的词。
*   通过在计算 Softmax **前**，将未来位置的点积分数设为 **负无穷大** 实现，使对应权重为 0。

## 6. Multi-Head Attention (多头注意力)

*   模型 **并行** 地进行多次 Attention 计算，每次使用 **不同** 的 `WQ`, `WK`, `WV` 矩阵。这称为 **Multi-Head Attention**。
*   **目的**: 每个 "Head" 学习关注输入序列中 **不同类型** 的关系或特征（语法、语义、位置等）。
*   **实现**:
    *   GPT-3 使用 96 个 Head。
    *   每个 Head 独立计算 Attention 输出。
    *   所有 Head 的输出结果 **拼接 (concatenate)** 在一起。
    *   通过一个最终的线性层 (Output Matrix) 整合。

## 7. 参数量与效率

*   Attention 相关的参数量很大 (Q, K, V 矩阵)，约占 GPT-3 总参数的 1/3。
*   但 **大部分** 参数实际上来自 Attention 层之间的 **多层感知机 (Multilayer Perceptron / Feed-Forward Network)** (下一章内容)。
*   **并行性**: Attention 机制高度 **可并行化**，非常适合 GPU 计算，是其关键优势。

## 8. 总结

*   Attention 是 Transformer 理解和利用 **上下文** 的核心机制。
*   通过 QKV 机制和加权求和，模型动态融合相关信息。
*   Multi-Head Attention 增强了模型捕捉复杂关系的能力。
*   其并行性设计是大型语言模型成功的关键因素之一。
